package main

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/Finoptimize/agentaflow-sro-community/pkg/gpu"
	"github.com/Finoptimize/agentaflow-sro-community/pkg/observability"
)

func main() {
	fmt.Println("=== AgentaFlow SRO Community - OpenTelemetry Tracing Demo ===")

	// Initialize tracing configuration
	config := &observability.TracingConfig{
		ServiceName:    "agentaflow-sro-demo",
		ServiceVersion: "0.1.0",
		Environment:    "demo",
		ExporterType:   "jaeger",
		JaegerEndpoint: "http://localhost:14268/api/traces",
		SampleRate:     1.0,
	}

	// Create tracing integration
	tracingIntegration, err := observability.NewTracingIntegration(config)
	if err != nil {
		log.Fatalf("Failed to initialize tracing: %v", err)
	}
	defer func() {
		ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
		defer cancel()
		if err := tracingIntegration.Shutdown(ctx); err != nil {
			log.Printf("Error shutting down tracing: %v", err)
		}
	}()

	// Get the tracing service for creating root spans
	tracingService := tracingIntegration.GetTracingService()

	// Create a root context for the demo
	ctx := context.Background()

	// Demonstrate distributed tracing across the platform
	fmt.Println("\nüîç Starting distributed tracing demo...")

	// 1. Initialize system components with tracing
	fmt.Println("\nüìä Initializing GPU Scheduler...")
	ctx, initSpan := tracingService.TraceAPIRequest(ctx, "demo.initialize_system", "/demo/init")

	// Create GPU scheduler
	scheduler := &gpu.Scheduler{}
	tracedScheduler := tracingIntegration.WrapGPUScheduler(scheduler)

	// Create metrics collector
	collector := &gpu.MetricsCollector{}
	tracedCollector := tracingIntegration.WrapMetricsCollector(collector)

	// Create monitoring service
	monitoring := &observability.MonitoringService{}
	tracedMonitoring := tracingIntegration.WrapMonitoringService(monitoring)

	initSpan.End()

	// 2. Register GPUs with distributed tracing
	fmt.Println("\nüñ•Ô∏è  Registering GPUs...")
	ctx, registerSpan := tracingService.TraceGPUScheduling(ctx, "demo.register_gpus", "")

	gpus := []*gpu.GPU{
		{
			ID:          "gpu-001",
			Name:        "NVIDIA RTX 4090",
			MemoryTotal: 24576,
			Available:   true,
		},
		{
			ID:          "gpu-002",
			Name:        "NVIDIA RTX 4080",
			MemoryTotal: 16384,
			Available:   true,
		},
	}

	for _, g := range gpus {
		if err := tracedScheduler.RegisterGPU(ctx, g); err != nil {
			log.Printf("Failed to register GPU %s: %v", g.ID, err)
		} else {
			fmt.Printf("   ‚úÖ Registered %s (%s)\n", g.Name, g.ID)
		}
	}
	registerSpan.End()

	// 3. Start metrics collection with tracing
	fmt.Println("\nüìà Starting metrics collection...")
	ctx, metricsSpan := tracingService.TraceMetricsCollection(ctx, "demo.start_metrics", 0)

	if err := tracedCollector.Start(ctx); err != nil {
		log.Printf("Failed to start metrics collector: %v", err)
	} else {
		fmt.Println("   ‚úÖ Metrics collector started")
	}
	metricsSpan.End()

	// 4. Submit workloads with distributed tracing
	fmt.Println("\n‚ö° Submitting AI workloads...")
	ctx, workloadSpan := tracingService.TraceGPUScheduling(ctx, "demo.submit_workloads", "")

	workloads := []*gpu.Workload{
		{
			ID:             "workload-001",
			Name:           "LLM Training - GPT Model",
			Priority:       1,
			MemoryRequired: 16384,
		},
		{
			ID:             "workload-002",
			Name:           "Computer Vision - Object Detection",
			Priority:       2,
			MemoryRequired: 8192,
		},
		{
			ID:             "workload-003",
			Name:           "Neural Style Transfer",
			Priority:       3,
			MemoryRequired: 4096,
		},
	}

	for _, w := range workloads {
		if err := tracedScheduler.SubmitWorkload(ctx, w); err != nil {
			log.Printf("Failed to submit workload %s: %v", w.ID, err)
		} else {
			fmt.Printf("   ‚úÖ Submitted %s\n", w.Name)
		}
	}
	workloadSpan.End()

	// 5. Perform GPU scheduling with tracing
	fmt.Println("\nüß† Executing GPU scheduling algorithm...")
	ctx, scheduleSpan := tracingService.TraceGPUScheduling(ctx, "demo.schedule_execution", "")

	if err := tracedScheduler.Schedule(ctx); err != nil {
		log.Printf("Scheduling failed: %v", err)
	} else {
		fmt.Println("   ‚úÖ Scheduling completed successfully")
	}
	scheduleSpan.End()

	// 6. Collect metrics with tracing
	fmt.Println("\nüìä Collecting GPU metrics...")
	ctx, collectSpan := tracingService.TraceMetricsCollection(ctx, "demo.collect_metrics", len(gpus))

	for _, g := range gpus {
		mockMetrics := &gpu.GPUMetrics{
			GPUID:          g.ID,
			UtilizationGPU: 75.5 + float64(len(g.ID)%20), // Mock utilization
			Temperature:    68.0 + float64(len(g.ID)%15), // Mock temperature
			MemoryUsed:     uint64(8192 + len(g.ID)*100), // Mock memory usage
		}

		if _, err := tracedCollector.CollectMetrics(ctx); err != nil {
			log.Printf("Failed to collect metrics for %s: %v", g.ID, err)
		} else {
			fmt.Printf("   üìà %s: %.1f%% util, %.1f¬∞C, %d MB used\n",
				g.Name, mockMetrics.UtilizationGPU, mockMetrics.Temperature, mockMetrics.MemoryUsed)
		}
	}
	collectSpan.End()

	// 7. Calculate costs with tracing
	fmt.Println("\nüí∞ Calculating operational costs...")
	ctx, costSpan := tracingService.TraceCostCalculation(ctx, "demo.cost_calculation", 2.5)

	costEntries := []observability.CostEntry{
		{
			Operation:  "LLM Training",
			GPUHours:   2.5,
			TokensUsed: 1500000,
			Cost:       12.50,
		},
		{
			Operation:  "Computer Vision",
			GPUHours:   1.2,
			TokensUsed: 750000,
			Cost:       6.00,
		},
	}

	for _, entry := range costEntries {
		tracedMonitoring.RecordCost(ctx, entry)
		fmt.Printf("   üí≥ %s: $%.2f (%.1f GPU hours)\n", entry.Operation, entry.Cost, entry.GPUHours)
	}
	costSpan.End()

	// 8. Get utilization metrics with tracing
	fmt.Println("\nüìä Retrieving system utilization...")
	ctx, utilizationSpan := tracingService.TraceGPUScheduling(ctx, "demo.get_utilization", "")

	if utilization, err := tracedScheduler.GetGPUUtilization(ctx); err != nil {
		log.Printf("Failed to get utilization: %v", err)
	} else {
		fmt.Printf("   üìà Overall GPU Utilization: %.1f%%\n", utilization)
	}
	utilizationSpan.End()

	// 9. Generate cost summary with tracing
	fmt.Println("\nüìã Generating cost summary...")
	endTime := time.Now()
	startTime := endTime.Add(-24 * time.Hour)

	summary := tracedMonitoring.GetCostSummary(ctx, startTime, endTime)
	totalCost, _ := summary["total_cost"].(float64)
	gpuHours, _ := summary["gpu_hours"].(float64)
	fmt.Printf("   üìä 24h Cost Summary: $%.2f (%.1f GPU hours)\n", totalCost, gpuHours)

	// 10. Health checks with tracing
	fmt.Println("\nüè• Performing health checks...")
	ctx, healthSpan := tracingService.TraceAPIRequest(ctx, "demo.health_check", "/health")

	healthData := tracingIntegration.HealthCheck()
	fmt.Printf("   ‚úÖ Tracing system health: %v\n", healthData["status"])
	healthSpan.End()

	// 11. Demonstrate nested spans and correlation
	fmt.Println("\nüîó Demonstrating span correlation...")
	ctx, parentSpan := tracingService.TraceAPIRequest(ctx, "demo.nested_operations", "/demo/nested")

	// Simulate nested operations that would happen in a real request
	func(ctx context.Context) {
		ctx, childSpan := tracingService.TraceGPUScheduling(ctx, "nested.gpu_check", "")
		defer childSpan.End()

		// Simulate some work
		time.Sleep(50 * time.Millisecond)

		func(ctx context.Context) {
			ctx, grandchildSpan := tracingService.TraceMetricsCollection(ctx, "nested.metrics_validate", 1)
			defer grandchildSpan.End()

			// Simulate metrics validation
			time.Sleep(25 * time.Millisecond)
		}(ctx)
	}(ctx)

	parentSpan.End()
	fmt.Println("   üîó Nested span operations completed")

	fmt.Println("\n‚ú® Demo completed! Check your tracing backend for detailed traces:")
	fmt.Println("   üîç Jaeger UI: http://localhost:16686")
	fmt.Println("   üìä All operations have been traced and correlated")
	fmt.Println("   üè∑Ô∏è  Trace attributes include GPU IDs, workload details, costs, and performance metrics")

	// Wait a moment for spans to be exported
	fmt.Println("\n‚è≥ Waiting for trace export...")
	time.Sleep(2 * time.Second)

	fmt.Println("\nüéâ AgentaFlow SRO Community - OpenTelemetry tracing demo completed successfully!")
	fmt.Println("   ‚úÖ GPU Scheduling operations traced")
	fmt.Println("   ‚úÖ Metrics Collection traced")
	fmt.Println("   ‚úÖ Cost Calculations traced")
	fmt.Println("   ‚úÖ API Requests traced")
	fmt.Println("   ‚úÖ Distributed tracing correlation demonstrated")
}
